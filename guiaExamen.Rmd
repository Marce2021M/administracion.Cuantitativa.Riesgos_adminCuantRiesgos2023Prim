```{r setup, include=FALSE}
# Cargamos librerías

library(PerformanceAnalytics)
library(zoo)
library(dplyr)

library(readxl)
library(openxlsx)
library(e1071)
```

Toda limpieza debe realizarse en el excel

Aquí solo se correrán procesos para agilizar el proceso en excel

ADVERTENCIA: SIEMPRE CHECAR LOS PARÁMETROS DE

-cuantilProb
-window_size
-ponderaciones
-nu
-m
-sheet

# Primer parcial

Primero cargamos el archivo de excel
```{r cargando datos}
# Set the path to the Excel file and the sheet name
file_path <- "/Users/marcelinosanchezrodriguez/itamRepositories/adminCuantRiesgos2023Prim/varDatos.xlsx"
sheet_name <- "Sheet1"

# Read the entire sheet into a data frame
sheet <- read_excel(file_path, sheet = sheet_name)

# Print the table
head(sheet)
summary(sheet)

```

Suponemos que recibiremos una tabla de excel con los precios, rendimientos y fechas sin NAs

## Cálculo Var HISTÓRICO 

Realizamos el cálculo de VaR histórico a lo largo de varios datos con una ventana temporal de 252 días para tener el registro de var a lo largo de la base de datos.

```{r}

# Agregamos window size para la funcion rollapply y poder hacer lo mismo que en excel
window_size <- 252

# Definimos cuantil a cierta probabilidad
cuantilProb <- .05

##-------------------------------------------------------------------

## VAR HISTÓRICO sobre una base larga de datos

varHist <- rollapply(data=sheet$returns,width= window_size, FUN=quantile, probs = .05, names= FALSE, align = "right")

#agregamos columna VaR histórico

sheet$varHist <- c(rep(NA, window_size -1), -varHist*100)

# para solo hacerlo una vez se utiliza lo siguiente

#quantile(sheet$returns, probs = cuantilProb)

```

## Cálculo Var PONDERADO

Realizamos el cálculo de VaR ponderado a lo largo de varios datos con una ventana temporal de 252 días para tener el registro de var a lo largo de la base de datos.

```{r}

## VAR HISTÓRICO PONDERADO

#crear serie de ponderados

#en este caso los del profe salen de una geométrica
nu <- 0.97

m <- window_size # es 252
ponde <- sort(dgeom(0:(window_size-1), 1-nu)/(1-nu^m), decreasing = F)


#función para calcular ponderado

varFuncPonde <- function(vectorDatos){
    #relacionando ponderaciones

    dataFrameAux <- data.frame(rend=vectorDatos, ponde=ponde) 
    
    #reordenando por rendimiento
    
    dataFrameAux <- dataFrameAux[order(dataFrameAux$rend, decreasing = F),] 
    
    #prob acumulada

    dataFrameAux$sumaAcumPonde <- cumsum(dataFrameAux$ponde) 
    
    #filtrando para encontrar el cuantil
    
    dataFrameAux<-dataFrameAux[dataFrameAux$sumaAcumPonde>=cuantilProb,] 
    
    #sacando el cuantil

    varPonderado<-head(dataFrameAux$rend, n=1) 

    return(-varPonderado[1])
}

# Calculate VaR histórico ponderado

varHistPonde <- rollapply(data=sheet$returns,width= window_size, FUN=varFuncPonde, align = "right")

# agrega a la tabla

sheet$varHistPonde <- c(rep(NA, window_size -1), varHistPonde*100)

# si solo queremos hacerlo una vez para un vector de datos

#varFuncPonde(sheet$returns)


```



## Calculamos expected shortfall del historical simulation

```{r}

# creamos función para calcular expected shortfall
esFunct <- function(vectorDatos){
    varAux <- as.numeric(quantile(vectorDatos, probs=cuantilProb, names=FALSE))
    esAux <- -vectorDatos[vectorDatos< varAux]
    return(mean(esAux)*100)
}

expecShortFall <- rollapply(data=sheet$returns, width=window_size, FUN=esFunct, align="right" )

# agrega a la tabla

data$expecShortFall <- c(rep(NA, window_size -1), expecShortFall)

# si queremos hacerlo una vez para un vector de datos

#esFunct(sheet$returns)


```

## Calculamos expected shortfall del historical simulation ponderado

```{r}
esFunctPonder <- function(vectorDatos){
    varAux <- varFuncPonde(vectorDatos)
    esAux <- -vectorDatos[vectorDatos< -varAux]
    return(mean(esAux)*100)
}

expecShortFallPonder <- rollapply(data=sheet$returns, width=window_size, FUN=esFunctPonder, align="right" )

# agrega a la tabla

data$expecShortFallPonder <- c(rep(NA, window_size -1), expecShortFallPonder)

# si queremos hacerlo una vez para un vector de datos

#esFunctPonder(sheet$returns)


```

## Calculamos Var y expecShortFall paramétrico


```{r}
#función iterativa
varFuncPar <- function(vectorDatos){
    varAux <- -sd(vectorDatos) * qnorm(cuantilProb)
    return(varAux*100)
}

varHistPar <- rollapply(data=sheet2$returns,width= window_size, FUN=varFuncPar, align = "right")

#agregamos columna VaR histórico paramétrico

data$varHistPar <- c(rep(NA, window_size -1), -varHistPar*100)

# si solo queremos hacerlo una vez para un vector de datos

#varFuncPar(sheet$returns)


#creamos funcion de expected shortfall paramétrico 

esFunctPar <- function(vectorDatos){
    es <- sd(vectorDatos) * dnorm(qnorm(cuantilProb)) / (cuantilProb)
    return(es*100)
}

expecShortFallPar <- rollapply(data=sheet$returns, width=window_size, FUN=esFunctPar, align="right" )

# agrega a la tabla

data$expecShortFallPar <- c(rep(NA, window_size -1), expecShortFallPar)

# si queremos hacerlo una vez para un vector de datos

#esFunctPar(sheet$returns)



```


## Calculamos Var y expecShortFall paramétrico calculando la VOL

```{r}

lambda <- 0.94  # ponderación de la volatilidad
# calculamos vol
volatAux <- var(sheet$returns[1:252]) # puede ser una que de el profe

varHistVolPar <- rep(1,length(sheet$returns)-251 ) # inicializamos vector de var
esHistVolPar <- rep(1,length(sheet$returns)-251 ) # inicializamos vector de expected shortfall

#poniendo el primer valor, también puede usarse para solo una vez

varHistVolPar[1] <- -sqrt(volatAux)*qnorm(cuantilProb)

esHistVolPar[1] <- sqrt(volatAux)*dnorm(qnorm(cuantilProb))/cuantilProb

for(i in 253:length(sheet$returns)){
    volatAux=lambda*volatAux+(1-lambda)*sheet$returns[i]**2
    varHistVolPar[i-251] <- -sqrt(volatAux)*qnorm(cuantilProb)

    esHistVolPar[i-251] <- sqrt(volatAux)*dnorm(qnorm(cuantilProb))/cuantilProb
}

# agrega a la tabla

data$varHistVolPar <- c(rep(NA, window_size -1), varHistVolPar*100)

data$esHistVolPar <- c(rep(NA, window_size -1), esHistVolPar*100)


```


## Calculamos Var y expecShortFall usando ajuste cornish-fisher

```{r}
lambda <- 0.94  # ponderación de la volatilidad
#variables iniciales para el for
zNormal <- qnorm(cuantilProb)

volatAux <- var(sheet$returns[1:252]) # puede ser una que de el profe
skewAux <- skewness(sheet$returns[1:252], type=2)
kurtAux <- kurtosis(sheet$returns[1:252], type = 2)

# inicializando los vectores
varCornisFisher <- rep(1,length(sheet$returns)-251 )
esCornisFisher <- rep(1,length(sheet$returns)-251 )

#poniendo el primer valor, también puede usarse para solo una vez

cornisFisherAux <- zNormal + (skewAux/6)*(zNormal**2 -1)+(kurtAux/24)*(zNormal**3 -3*zNormal)-((skewAux**2)/36)*(2*(zNormal**3)-5*zNormal)

esCornisFisherAux <- -(dnorm(cornisFisherAux)/cuantilProb)*(1+(skewAux/6)*(cornisFisherAux)^3 + (kurtAux/24)*(cornisFisherAux^4-2*cornisFisherAux^2-1))

varCornisFisherAux <- -cornisFisherAux*sqrt(volatAux)

for(i in 253:length(sheet$returns)){
    volatAux=lambda*volatAux+(1-lambda)*sheet$returns[i]**2 #usamos vol de JP Morgan
    skewAux <- skewness(sheet$returns[(i-251):i], type = 2)
    kurtAux <- kurtosis(sheet$returns[(i-251):i], type = 2)

    cornisFisherAux <- zNormal + (skewAux/6)*(zNormal**2 -1)+(kurtAux/24)*(zNormal**3 -3*zNormal)-((skewAux**2)/36)*(2*(zNormal**3)-5*zNormal)
    esCornisFisherAux <- -(dnorm(cornisFisherAux)/cuantilProb)*(1+(skewAux/6)*(cornisFisherAux)^3 + (kurtAux/24)*(cornisFisherAux^4-2*cornisFisherAux^2-1))

    varCornisFisher[i-251] <--cornisFisherAux*sqrt(volatAux)*100
    esCornisFisher[i-251] <- esCornisFisherAux*100
}

# agrega a la tabla

sheet$varCornisFisher <- c(rep(NA, window_size -1), varCornisFisher*100)

sheet$varCornisFisher <- c(rep(NA, window_size -1), esCornisFisher*100)


```

## VAR calculado por SIMULACIÓN MONTECARLO

Suponemos que recibiremos una tabla de rendimientos de distintas empresas ya filtrada y lista para usarse. Esta tabla tiene rendimientos por fechas.

CUIDADO  si no está bien limpia o con los ajustes necesarios

```{r cargamos datos}
sheet2 <- read_excel("/Users/marcelinosanchezrodriguez/Documents/Itam/adminDeRiesgos/Clase VAR Portafolio.xlsm", sheet = "pruebas")
sheet2 <- sheet2[,-1] # quitamos la primera columna que es la fecha
sheet2 <- sheet2[-nrow(sheet2),] # quitamos la última fila que tiene NA 
#CHECAR PUREZAS
```


```{r}
n <- 10 #número de activos

wPortafolio <- rep(1/n,n) # pesos del portafolio

#1.- Calculamos la matriz de volatilidades para cada activo -----------------------------------------------------

lambda <- 0.94  # ponderación de la volatilidad
volatAuxInic <- rep(.0004,n) # inicializamos vector de volatilidades inicial
df_volatilidades <- data.frame(matrix(NA, nrow = nrow(sheet2)+1, ncol = ncol(sheet2)))

colnames(df_volatilidades) <- colnames(sheet2)

#inicializando dataframe de volatilidades
df_volatilidades[1,] <- volatAuxInic

for (i in 2:(nrow(sheet2)+1)) {
    df_volatilidades[i,] <- lambda * df_volatilidades[i-1,] + (1 - lambda) * (sheet2[i-1,])** 2
}

#2.Normalizamos los rendimientos de cada activo, suponemos que tienen media cero-------------------------------------

df_rendNormalizados <- mapply("/", sheet2, sqrt(df_volatilidades[-nrow(df_volatilidades),]))

#3.- Calculamos las volatilidades finales para después

volatFinales <- as.vector(as.matrix(sqrt(df_volatilidades[nrow(df_volatilidades),])))

#4.- Calculamos la matriz de correlaciones-------------------------------------------------------------------------

matrizCorrelaciones <- cor(df_rendNormalizados)

#5.-Creamos matriz de cholesky a partir de matriz de correlaciones--------------------------------------------------

matrizCholesky <- chol(matrizCorrelaciones)

# Quitar los nombres de las filas y columnas
dimnames(matrizCholesky) <- list(NULL, NULL)

#6.- Simulamos los rendimientos de cada activo---------------------------------------------------------------------

set.seed(1234)

nSimulaciones <- 1000 # número de simulaciones

#inicializamos matriz de simulaciones

matrizSimulaciones <- matrix(NA, nrow = nSimulaciones, ncol = n)

# matriz de 2000 números aleatorios de una normal estándar

mat <- matrix(rnorm( 2000 * n ), nrow = 2000, ncol = n) 

#7.-Correlacionamos simulaciones

matSimCorr <- mat %*% matrizCholesky

#8.- Calculamos los rendimientos simulados con la vol final

matrizSimRenCorr <- sweep(matSimCorr, 2, volatFinales, "*")

#9.- Calculamos los rendimientos del portafolio con rendimientos simulados

vectorSimRenPort <- matrizSimRenCorr %*% wPortafolio

#10.- Calculamos el VaR del portafolio

varPort <- -quantile(vectorSimRenPort, 0.05)*100

```

Ahora simularemos varias veces para determinar la centralidad del estimador del VAR por MONTECARLO

```{r}

simulacionesVar <- function(sheet2){
    #set.seed(1234)

    nSimulaciones <- 1000 # número de simulaciones

    #inicializamos matriz de simulaciones

    matrizSimulaciones <- matrix(NA, nrow = nSimulaciones, ncol = n)

    # matriz de 2000 números aleatorios de una normal estándar

    mat <- matrix(rnorm( 2000 * n ), nrow = 2000, ncol = n) 

    #7.-Correlacionamos simulaciones

    matSimCorr <- mat %*% matrizCholesky

    #8.- Calculamos los rendimientos simulados con la vol final

    matrizSimRenCorr <- sweep(matSimCorr, 2, volatFinales, "*")

    #9.- Calculamos los rendimientos del portafolio con rendimientos simulados

    vectorSimRenPort <- matrizSimRenCorr %*% wPortafolio

    #10.- Calculamos el VaR del portafolio

    varPort <- -quantile(vectorSimRenPort, 0.05)*100

    return(varPort)
}

simulacionesVar(sheet2)

```

```{r}
#11.- Calculamos el promedio acumlado de los VAR

mSimulaciones <- 10000
vectorSimVarPort<- rep(NA, mSimulaciones)

for(i in 1:mSimulaciones){
    vectorSimVarPort[i] <- -quantile(simulacionesVar(sheet2), 0.05)
}

vectorSimVarPortCumMean <- cummean(vectorSimVarPort)

plot(vectorSimVarPortCumMean, type = "l", col = "blue", lwd = 2, xlab = "Número de simulación", ylab = "Cumsum VaR Portafolio")

hist(vectorSimVarPort, breaks = 100, col = "blue", xlab = "VaR Portafolio", main = "Histograma de VaR Portafolio")
quantile(vectorSimVarPort, c(0.05, 0.95))```

```



## GUARDAMOS
Ahora procedemos a guardarlo en excel

```{r}

# Load the existing workbook
wb <- loadWorkbook("/Users/marcelinosanchezrodriguez/itamRepositories/adminCuantRiesgos2023Prim/varDatos.xlsx")

# Add a new sheet to the workbook
addWorksheet(wb, sheetName = "NewSheet")

# Write data to the new sheet
data <- data.frame(sheet)
writeData(wb, sheet = "NewSheet", x = data)

# Save the workbook to a file
saveWorkbook(wb, "/Users/marcelinosanchezrodriguez/itamRepositories/adminCuantRiesgos2023Prim/varDatos.xlsx", overwrite = TRUE)

```


## Cálculo de VOLATILIDADES
```{r cargamos datos}
# Set the path to the Excel file and the sheet name
file_path <- "/Users/marcelinosanchezrodriguez/Documents/Itam/adminDeRiesgos/Clase Riesgos Vol.xlsx"
sheet_name <- "pruebas"

# Read the entire sheet into a data frame
sheet3 <- read_excel(file_path, sheet = sheet_name)

# Print the table
head(sheet3)
summary(sheet3)
```

```{r preparamos modelos}

#DATOS se refiere a rendimientos de activos
#resultado se refiere a volatilidades de activos

sacaLogLikelihood <- function(vector,datos){
    vectorAux <- rep(NA, length(datos)-1)
    vectorAux <- -(1/2)*(log(vector[-1])+datos[-1]^2/vector[-1])
    return(sum(vectorAux))
}

modeloGarch <- function(semilla=.0004, params, datos){
    resultado <- rep(semilla, length(datos))
    #params1 es omega, params2 es alpha, params3 es beta

    for(i in 2:length(datos)){
        resultado[i] <- params[1] + params[2]*datos[i-1]^2 + params[3]*resultado[i-1]
    }
    return(resultado)
}

modeloLeverage <- function(semilla=.04, params, datos){
    resultado <- rep(semilla, length(datos))
    #params1 es omega, params2 es alpha, params3 es beta, params4 es theta
    for(i in 2:length(datos)){
        resultado[i] <- params[1] +params[2]*(datos[i-1]-params[4]*sqrt(resultado[i-1]))^2 + params[3]*resultado[i-1]
    }
    return(resultado)
}


```

```{r optimizamos}
library(nloptr)

datos <- sheet3$Rt

n<-4 #número de parametros

# Define the objective function
objective <- function(params) {
  resultado <- -sacaLogLikelihood(modeloGarch(semilla=.0004, params, datos), datos)

  return(resultado)
}

objective2 <- function(params) {
  resultado <- -sacaLogLikelihood(modeloLeverage(semilla=.0004, params, datos), datos)

  return(resultado)
}
constraints <- function(x) {
  # Example constraint: the sum of variables should be less than or equal to 1
  return(sum(x) - 1)
}

# Define the initial guess for the variables
initial_guess <- c(.000005,0.070000,0.850000,0.500000)  #

# Perform the optimization
result <- nloptr(x0 = initial_guess,
                 eval_f = objective2,
                 lb = rep(0, n),  # Lower bounds for the variables
                 ub = rep(1, n),  # Upper bounds for the variables
                 #eval_g_ineq = constraints,
                 opts=list("algorithm" = "NLOPT_LN_COBYLA"))  # Use GRG Nonlinear method

# Extract the optimized variables and objective value
optimal_variables <- result$solution
optimal_objective <- result$objective

# Print the results
print(optimal_variables)
print(optimal_objective)

```


Y por último comparamos los modelos
```{r prueba de hipotesis}
nivel_confianza <- 0.99
paramsExtra <- 1
valorCrit <- qchisq(nivel_confianza, df = paramsExtra)

estadistico <- 2*(objective(optimal_variables) - objective2(optimal_variables))
```

# Parcial 2

Creacción de curvas

```{r}
# Set the path to the Excel file and the sheet namE

sheet5SOFR <- read_excel("/Users/marcelinosanchezrodriguez/Documents/Itam/adminDeRiesgos/estudioFinalCheck/Creación de Curvas Licenciatura-4-2.xlsm", sheet = "pruebaSOFR")
```

```{r funciones importantes}

interpolaitam <- function(matriz, coldatos, pb) {
  r <- nrow(matriz)
  temp <- 0
  
  for (i in 1:(r - 1)) {
    if (pb >= matriz[i, 1] && pb <= matriz[i + 1, 1]) {
      p1 <- matriz[i, 1]
      p2 <- matriz[i + 1, 1]
      y1 <- matriz[i, coldatos]
      y2 <- matriz[i + 1, coldatos]
      
      m <- (y2 - y1) / (p2 - p1)
      
      temp <- y1 + m * (pb - p1)
      
      break
    }
  }
  
  if (pb < matriz[1, 1]) {
    temp <- 0
  } else if (pb > matriz[r, 1]) {
    temp <- matriz[r, coldatos]
  }
  
  return(as.numeric(temp))
}

fwd <- function(matriz, coldatos, pc, pl) {
  tc <- interpolaitam(matriz, coldatos, pc)  # Tasa Corta
  tl <- interpolaitam(matriz, coldatos, pl)  # Tasa Larga
  
  fwd <- ((1 + tl * pl / 360) / (1 + tc * pc / 360) - 1) * 360 / (pl - pc)
  
  return(fwd)
}



```

## CURVA VALUACIÓN USD COL USD
```{r}
library(lubridate)

# construimos columna de dias
dias30_360 <- c(c(1, 7, 14, 21, 30, 60, 90, 120, 150, 180, 210, 240, 270, 300, 330, 360),seq(720,18000,360))
)

# construimos columna de dias act 30/360

future_date <- lapply(dias30_360[-(1:4)], function(d) Sys.Date() + months(d/30)) 

diasAct360 <- unlist(c(dias30_360[1:4], lapply(future_date, function(d) as.numeric(d - Sys.Date()))))

# creamos columna de días intermedios
diasInterm <- diasAct360[-1]-diasAct360[-length(diasAct360)]
diasInterm <- c(rep(NA,15),diasAct360[16],diasInterm[-(1:15)])

#creamos columna de iIRS

tasaiIRS <- sapply(diasAct360, function(dia) {
  interpolaitam(sheet5SOFR, 4, dia)
})

#

```


# Parcial 3

Valuaciones de bonos y duraciones

NOTA: El archivo que se debe cargar es la tabla con los datos de los bonos.

```{r cargamos datos}
library(lubridate)
sheet4 <- read_excel("/Users/marcelinosanchezrodriguez/Documents/Itam/adminDeRiesgos/estudioFinalCheck/Copy of Book2-5.xlsx", sheet = "baseprueba")


```

```{r}
#inicializando variables para valuación para pruebas

(fecha_de_operacion <- Sys.Date())

tPositiva <- 0

(fecha_de_liquidacion <- fecha_de_operacion + tPositiva)


serie <- "M 341123" # elegir una serie de sheet4$Ticker

(fecha_de_vencimiento <- as.Date(sheet4[sheet4$Ticker == serie,"Fecha de vencimiento"]$'Fecha de vencimiento'))

(dias_por_vencer <- as.numeric(fecha_de_vencimiento-fecha_de_liquidacion))

dias_cupon <- 182

dias_año <- 360

valor_nominal <- 100

(tasa_cupon <- sheet4[sheet4$Ticker == serie, "TasaCuponVigente"]$'TasaCuponVigente')

yieldTM <- .089

(cupones_a_recibir <- dias_por_vencer/dias_cupon)

(cupones_por_cobrar <- ceiling(cupones_a_recibir))

(dias_deveng_no_cobrados <- (cupones_por_cobrar-cupones_a_recibir)*dias_cupon)

(cupon_monetario <- valor_nominal*tasa_cupon*dias_cupon/dias_año)

(capitalizacion <- dias_año/dias_cupon)

(tasa_efectiva <- yieldTM/capitalizacion)

(factor_de_descuento <- 1/(1+tasa_efectiva))
```

```{r}
funcionAsignaVars <- function(sheet4,serie){
    fecha_de_operacion <- Sys.Date()

    tPositiva <- 0

    fecha_de_liquidacion <- fecha_de_operacion + tPositiva

    serie <- "M 341123" # elegir una serie de sheet4$Ticker

    fecha_de_vencimiento <- as.Date(sheet4[sheet4$Ticker == serie,"Fecha de vencimiento"]$'Fecha de vencimiento')

    dias_por_vencer <- as.numeric(fecha_de_vencimiento-fecha_de_liquidacion)

    dias_cupon <- 182

    dias_año <- 360

    valor_nominal <- 100

    tasa_cupon <- sheet4[sheet4$Ticker == serie, "TasaCuponVigente"]$'TasaCuponVigente'

    yieldTM <- .089

    cupones_a_recibir <- dias_por_vencer/dias_cupon

    cupones_por_cobrar <- ceiling(cupones_a_recibir)

    dias_deveng_no_cobrados <- (cupones_por_cobrar-cupones_a_recibir)*dias_cupon

    cupon_monetario <- valor_nominal*tasa_cupon*dias_cupon/dias_año

    capitalizacion <- dias_año/dias_cupon

    tasa_efectiva <- yieldTM/capitalizacion

    factor_de_descuento <- 1/(1+tasa_efectiva)

}

funcionBono1 <- function(serie, sheet4){
    funcionAsignaVars(sheet4,serie)

    vectorCupon <- 0:cupones_por_cobrar

    vectorFechaCupon <- rep(fecha_de_vencimiento, length(vectorCupon))
    for (i in 1:length(vectorCupon)){
        vectorFechaCupon[length(vectorCupon)-i] <- vectorFechaCupon[length(vectorCupon)-i+1] - dias_cupon
    }

    vectorDiasPorVencer <- as.numeric(vectorFechaCupon -  fecha_de_liquidacion)
    vectorDiasPorVencer[1] <- NA

    vectorDiasCupon <- rep( NA, length(vectorCupon))
    for(i in 2:length(vectorCupon)){
        vectorDiasCupon[i] <- as.numeric(vectorFechaCupon[i]-vectorFechaCupon[i-1])
    }

    vectorFlujos <- rep(cupon_monetario, length(vectorCupon))
    vectorFlujos[1] <- NA
    vectorFlujos[length(vectorCupon)] <- cupon_monetario + valor_nominal

    vectorFlujosDesc <- rep(factor_de_descuento, length(vectorCupon))
    for (i in 1:length(vectorCupon)){
        vectorFlujosDesc[i] <- vectorFlujosDesc[i]^(vectorDiasPorVencer[i]/dias_cupon)
    }

    vectorValorPresente <- vectorFlujos*vectorFlujosDesc

    valorSucioBono <- sum(vectorFlujos*vectorFlujosDesc, na.rm = TRUE)

    vectorTiempo <- vectorDiasPorVencer/dias_cupon

    intereses_devengados <- cupon_monetario/dias_cupon*dias_deveng_no_cobrados

    valorLimpioBono <- valorSucioBono - intereses_devengados

    duracionMacaulay.m <- sum(vectorValorPresente*vectorTiempo, na.rm = T)/valorSucioBono

    duracionMacaulay.y <- duracionMacaulay.m/(capitalizacion)

    duracionModificada <- duracionMacaulay.y/(1+tasa_efectiva)

    duracion.simple <- ((cupon_monetario/tasa_efectiva^2)*(1-factor_de_descuento^cupones_a_recibir)+((cupones_a_recibir*(valor_nominal-cupon_monetario/tasa_efectiva))*factor_de_descuento^(cupones_a_recibir+1)))/valorSucioBono/capitalizacion

    convexidadBono <- ((2*cupon_monetario/tasa_efectiva^3)*(1-factor_de_descuento^cupones_a_recibir)-(2*cupon_monetario*cupones_a_recibir*factor_de_descuento^(cupones_a_recibir+1)/tasa_efectiva^2)+(cupones_a_recibir*(cupones_a_recibir+1)*(valor_nominal-cupon_monetario/tasa_efectiva))*factor_de_descuento^(cupones_a_recibir+2))/valorSucioBono/(capitalizacion^2)

}


funcionBono2 <- function(serie, sheet4){
    funcionAsignaVars(sheet4,serie)

    valorSucioBono <- (cupon_monetario*(1-factor_de_descuento^cupones_por_cobrar)/tasa_efectiva+valor_nominal*factor_de_descuento^cupones_por_cobrar)*(1+tasa_efectiva)^(dias_deveng_no_cobrados/dias_cupon)

    intereses_devengados <- cupon_monetario/dias_cupon*dias_deveng_no_cobrados

    valorLimpioBono <- valorSucioBono - intereses_devengados

}

calculoDuraciones <- function(serie, sheet4) {
    cambioPorcentualTasa <- .01

    cambioPrecioAjusteDuracion <- -duracion.simple*cambioPorcentualTasa

    cambioPrecioAjusteYconvex <-cambioPrecioAjusteDuracion + .5*convexidadBono*cambioPorcentualTasa^2

    aprox_precio_duracion <- valorSucioBono*(1+cambioPrecioAjusteDuracion)

    aprox_precio_duracion_convexidad <- valorSucioBono*(1+ cambioPrecioAjusteYconvex)

}


```

```{r}


cambioPorcentualTasa <- .01

cambioPrecioAjusteDuracion <- -duracion.simple*cambioPorcentualTasa

cambioPrecioAjusteYconvex <-cambioPrecioAjusteDuracion + .5*convexidadBono*cambioPorcentualTasa^2

(aprox_precio_duracion <- valorSucioBono*(1+cambioPrecioAjusteDuracion))

(aprox_precio_duracion_convexidad <- valorSucioBono*(1+ cambioPrecioAjusteYconvex))

```

